{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net for vehicle detection \n",
    "\n",
    "## This is the notebook with the training code\n",
    "\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook , we will implement and train an  U-net for detecting vehicles in a video stream of images provided by Udacity. U-net is a encoder-decoder type of network for pixel-wise predictions. UNet are special Convets: receptive fields after convolution are concatenated with the receptive fields in up-convolving process. This allows the network to use features from lower layers and features from up-convolution. This up-convolution makes training harder in the sense that much more memory is required as in standard Conv-Nets where only downconvolution is done.  U-nets are used extensively for biomedical applications to detect cancer, kidney pathologies and tracking cells and so on. U-net has proven to be very powerful segmentation tool.\n",
    "\n",
    "<img src='output_images/u-net-architecture.png'>\n",
    "U-net, taken from http://lmb.informatik.uni-freiburg.de/Publications/2015/RFB15a/ \n",
    "\n",
    "\n",
    "The input to U-net is a resized 960X640 3-channel RGB image and output is 960X640 1-channel mask of predictions. We wanted the predictions to reflect probability of a pixel being a vehicle or not, so we used an activation function of sigmoid on the last layer.\n",
    "\n",
    "The solution in this notebook is based in the original research paper on [U-net](http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/) and the prize winning submission to kaggleâ€™s ultrasound segmentation challenge. The UNet-Code is based on this repository https://github.com/orobix/retina-unet\n",
    "\n",
    "\n",
    "## The Data\n",
    "\n",
    "We used annotated vehicle data set provided by [Udacity](https://www.udacity.com/). The [4.5 GB data set](https://github.com/udacity/self-driving-car/tree/master/annotation) was composed of frames collected from two of videos while driving the Udacity car around Mountain View area in heavy traffic. The data set contained a label file with bounding boxes marking other cars, trucks and pedestrians. The entire data set was comprised of about 22000 images. We combined cars and trucks into one class vehicle, and dropped all the bounding boxes for pedestrians. For each image a set of bounding boxes is provided.\n",
    "\n",
    "\n",
    "\n",
    "## Data preparation and augmentation\n",
    "\n",
    "Frames were obtained from a video feed, therefor shuffling is very important.  Data is splited into training and testing data sets, 2000 images are used for testing. Data augmentation on training data:\n",
    "\n",
    "- translation to account for cars beeing at different locations\n",
    "- brightness to account for differenct lightning conditions\n",
    "- stretching\n",
    "\n",
    "\n",
    "## Training \n",
    "Goal is to train the UNet to identify the bounding boxes of the cars in the image. That means that it shall learn to generate a mask which highlights all cars in an image. I choose image sizes of 640x980 and 480x720 for training. For the large image size I trained on a titan X pascal GPU with a batch size of 8 (larger batch sizes raise an out of memory error) and the the smaller image size I trained on a GTX1080 GPU with a batch size of 8. In both cases the training time for 1000 epochs where about 160s and 106 s. I trained for several hundred epochs. I used Keras with tensorflow backed and used approximate Intersection over Union (IoU) between the network output and target mask as objective function.\n",
    "\n",
    "## Remarks\n",
    "\n",
    "As in  many cases preparing the data and training a conv net is quite straighforward. The only difference here is the special UNet structure and that we train a deep network to do image segmentation and not image classification.  Compared to the complicated feature engineering with color histograms, HOG, and the sliding windowing technique with the classical image processing approach in the CarND P5 project it is fairly simple and no tuning and so on is required this stage! We will see in the notebook which does the car dectection that using the pretrained Unet model it is really very simple and powerful and very robust.\n",
    "\n",
    "## Additional links:\n",
    "\n",
    "1. U-Net: Convolutional Networks for Biomedical Image Segmentation: http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/\n",
    "2. Good collection of various segmentation models: https://handong1587.github.io/deep_learning/2015/10/09/segmentation.html\n",
    "3. Original prize winning submission to Kaggle https://github.com/jocicmarko/ultrasound-nerve-segmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "% matplotlib inline\n",
    "import glob\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout,Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from scipy.ndimage.measurements import label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_label = ['object-dataset','object-detection-crowdai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load label data crowed ai\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_files1 = pd.read_csv(dir_label[1]+'/labels.csv', header=0)\n",
    "df_vehicles1 = df_files1[(df_files1['Label']=='Car') | (df_files1['Label']=='Truck')].reset_index()\n",
    "df_vehicles1 = df_vehicles1.drop('index', 1)\n",
    "df_vehicles1['File_Path'] =  dir_label[1] + '/' +df_vehicles1['Frame']\n",
    "df_vehicles1 = df_vehicles1.drop('Preview URL', 1)\n",
    "print(dir_label[1])\n",
    "df_vehicles1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### #load label data from second source\n",
    "### Renamed frames and labels to match crowd-awi source \n",
    "names=['Frame',  'xmin', 'xmax', 'ymin','ymax', 'ind', 'Label','RM']#, 'Color']\n",
    "df_files2 = pd.read_csv('object-dataset/labels.csv', header=None,names=names,sep='\\s+')\n",
    "#df_files2.columns= ['Frame',  'xmin', 'xmax', 'ymin','ymax', 'ind', 'Label','RM', 'XX']\n",
    "df_vehicles2 = df_files2[(df_files2['Label']=='car') | (df_files2['Label']=='truck')].reset_index()\n",
    "df_vehicles2 = df_vehicles2.drop('index', 1)\n",
    "df_vehicles2 = df_vehicles2.drop('RM', 1)\n",
    "df_vehicles2 = df_vehicles2.drop('ind', 1)\n",
    "\n",
    "df_vehicles2['File_Path'] = dir_label[0] + '/' +df_vehicles2['Frame']\n",
    "\n",
    "df_vehicles2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### concat both data frames\n",
    "df_vehicles = pd.concat([df_vehicles1,df_vehicles2]).reset_index()\n",
    "df_vehicles = df_vehicles.drop('index', 1)\n",
    "df_vehicles.columns =['File_Path','Frame','Label','ymin','xmin','ymax','xmax']\n",
    "df_vehicles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Augmentation functions \n",
    "\n",
    "def translate_image(image,bb_boxes_f,trans_range):\n",
    "    bb_boxes_f = bb_boxes_f.copy(deep=True)\n",
    "    tr_x = trans_range*np.random.uniform()-trans_range/2\n",
    "    tr_y = trans_range*np.random.uniform()-trans_range/2\n",
    "\n",
    "    Trans_M = np.float32([[1,0,tr_x],[0,1,tr_y]])\n",
    "    rows,cols,channels = image.shape\n",
    "    bb_boxes_f['xmin'] = bb_boxes_f['xmin']+tr_x\n",
    "    bb_boxes_f['xmax'] = bb_boxes_f['xmax']+tr_x\n",
    "    bb_boxes_f['ymin'] = bb_boxes_f['ymin']+tr_y\n",
    "    bb_boxes_f['ymax'] = bb_boxes_f['ymax']+tr_y    \n",
    "    image_tr = cv2.warpAffine(image,Trans_M,(cols,rows))    \n",
    "    return image_tr,bb_boxes_f\n",
    "\n",
    "\n",
    "def stretch_image(img,bb_boxes_f,scale_range):\n",
    "    bb_boxes_f = bb_boxes_f.copy(deep=True)\n",
    "    \n",
    "    tr_x1 = scale_range*np.random.uniform()\n",
    "    tr_y1 = scale_range*np.random.uniform()\n",
    "    p1 = (tr_x1,tr_y1)\n",
    "    tr_x2 = scale_range*np.random.uniform()\n",
    "    tr_y2 = scale_range*np.random.uniform()\n",
    "    p2 = (img.shape[1]-tr_x2,tr_y1)\n",
    "\n",
    "    p3 = (img.shape[1]-tr_x2,img.shape[0]-tr_y2)\n",
    "    p4 = (tr_x1,img.shape[0]-tr_y2)\n",
    "\n",
    "    pts1 = np.float32([[p1[0],p1[1]],[p2[0],p2[1]],\n",
    "                   [p3[0],p3[1]],[p4[0],p4[1]]])\n",
    "    pts2 = np.float32([[0,0],[img.shape[1],0], [img.shape[1],img.shape[0]],\n",
    "                   [0,img.shape[0]] ] )\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "    img = cv2.warpPerspective(img,M,(img.shape[1],img.shape[0]))\n",
    "    img = np.array(img,dtype=np.uint8)\n",
    "    \n",
    "    bb_boxes_f['xmin'] = (bb_boxes_f['xmin'] - p1[0])/(p2[0]-p1[0])*img.shape[1]\n",
    "    bb_boxes_f['xmax'] = (bb_boxes_f['xmax'] - p1[0])/(p2[0]-p1[0])*img.shape[1]\n",
    "    bb_boxes_f['ymin'] = (bb_boxes_f['ymin'] - p1[1])/(p3[1]-p1[1])*img.shape[0]\n",
    "    bb_boxes_f['ymax'] = (bb_boxes_f['ymax'] - p1[1])/(p3[1]-p1[1])*img.shape[0]\n",
    "    \n",
    "    return img,bb_boxes_f\n",
    "\n",
    "def augment_brightness(image):\n",
    "    image1 = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    random_bright = .25+np.random.uniform()\n",
    "    image1[:,:,2] = image1[:,:,2]*random_bright\n",
    "    image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2RGB)\n",
    "    return image1\n",
    "\n",
    "\n",
    "def load_image_name(df,ind,size=(640,300),augmentation = False,trans_range = 20,scale_range=20):\n",
    " \n",
    "    file_name = df['File_Path'][ind]\n",
    "    img = cv2.imread(file_name)\n",
    "    img_size = np.shape(img)\n",
    "    \n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img,size)\n",
    "    name_str = file_name.split('/')\n",
    "    name_str = name_str[-1]\n",
    "    bb_boxes = df[df['Frame'] == name_str].reset_index()\n",
    "    img_size_post = np.shape(img)\n",
    "    \n",
    "    if augmentation == True:\n",
    "        img,bb_boxes = translate_image(img,bb_boxes,trans_range)\n",
    "        img,bb_boxes = stretch_image(img,bb_boxes,scale_range)\n",
    "        img = augment_brightness(img)\n",
    "        \n",
    "    bb_boxes['xmin'] = np.round(bb_boxes['xmin']/img_size[1]*img_size_post[1])\n",
    "    bb_boxes['xmax'] = np.round(bb_boxes['xmax']/img_size[1]*img_size_post[1])\n",
    "    bb_boxes['ymin'] = np.round(bb_boxes['ymin']/img_size[0]*img_size_post[0])\n",
    "    bb_boxes['ymax'] = np.round(bb_boxes['ymax']/img_size[0]*img_size_post[0])\n",
    "    bb_boxes['Area'] = (bb_boxes['xmax']- bb_boxes['xmin'])*(bb_boxes['ymax']- bb_boxes['ymin']) \n",
    "    return name_str,img,bb_boxes\n",
    "\n",
    "\n",
    "def get_mask_segmentation(img,bb_boxes_f):\n",
    "    img_mask = np.zeros_like(img[:,:,0])\n",
    "    for i in range(len(bb_boxes_f)):\n",
    "      \n",
    "        bb_box_i = [bb_boxes_f.iloc[i]['xmin'],bb_boxes_f.iloc[i]['ymin'],\n",
    "                bb_boxes_f.iloc[i]['xmax'],bb_boxes_f.iloc[i]['ymax']]\n",
    "        img_mask[bb_box_i[1]:bb_box_i[3],bb_box_i[0]:bb_box_i[2]]= 1.\n",
    "        img_mask = np.reshape(img_mask,(np.shape(img_mask)[0],np.shape(img_mask)[1],1))\n",
    "    return img_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_bbox(bb_boxes,ind_bb,color='r',linewidth=2):\n",
    "    bb_box_i = [bb_boxes.iloc[ind_bb]['xmin'],\n",
    "                bb_boxes.iloc[ind_bb]['ymin'],\n",
    "                bb_boxes.iloc[ind_bb]['xmax'],\n",
    "                bb_boxes.iloc[ind_bb]['ymax']]\n",
    "    plt.plot([bb_box_i[0],bb_box_i[2],bb_box_i[2],bb_box_i[0],bb_box_i[0]],\n",
    "             [bb_box_i[1],bb_box_i[1],bb_box_i[3],bb_box_i[3],bb_box_i[1]],\n",
    "             color,linewidth=linewidth)\n",
    "    \n",
    "def plot_img_bbox(img,bb_boxes):\n",
    "    plt.imshow(img)\n",
    "    for i in range(len(bb_boxes)):\n",
    "        plot_bbox(bb_boxes,i,'b')\n",
    "    \n",
    "        bb_box_i = [bb_boxes.iloc[i]['xmin'],bb_boxes.iloc[i]['ymin'],\n",
    "                    bb_boxes.iloc[i]['xmax'],bb_boxes.iloc[i]['ymax']]\n",
    "    plt.axis('off');\n",
    "\n",
    "def plot_image_mask(img,img_mask):\n",
    "    img = np.array(img,dtype=np.uint8)\n",
    "    img_mask = np.array(img_mask,dtype=np.uint8)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(img_mask[:,:,0])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(cv2.bitwise_and(img,img,mask=img_mask));\n",
    "    plt.axis('off')\n",
    "    plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Testing translation and stretching augmentations\n",
    "\n",
    "name,img,bb_boxes = load_image_name(df_vehicles,1,augmentation=False,trans_range=10,scale_range=0)\n",
    "\n",
    "tr_x1 = 80\n",
    "tr_y1 = 30\n",
    "tr_x2 = 40\n",
    "tr_y2 = 20\n",
    "\n",
    "p1 = (tr_x1,tr_y1)\n",
    "p2 = (img.shape[1]-tr_x2,tr_y1)\n",
    "\n",
    "p3 = (img.shape[1]-tr_x2,img.shape[0]-tr_y2)\n",
    "p4 = (tr_x1,img.shape[0]-tr_y2)\n",
    "\n",
    "pts1 = np.float32([[p1[0],p1[1]],\n",
    "                   [p2[0],p2[1]],\n",
    "                   [p3[0],p3[1]],\n",
    "                   [p4[0],p4[1]]])\n",
    "pts2 = np.float32([[0,0],\n",
    "                   [img.shape[1],0],\n",
    "                   [img.shape[1],img.shape[0]],[0,img.shape[0]] ]\n",
    "                   )\n",
    "\n",
    "M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "dst = cv2.warpPerspective(img,M,(img.shape[1],img.shape[0]))\n",
    "dst = np.array(dst,dtype=np.uint8)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18,12))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "for i in range(len(bb_boxes)):\n",
    "    plot_bbox(bb_boxes,i,'b')\n",
    "    \n",
    "    bb_box_i = [bb_boxes.iloc[i]['xmin'],bb_boxes.iloc[i]['ymin'],\n",
    "                bb_boxes.iloc[i]['xmax'],bb_boxes.iloc[i]['ymax']]\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(dst)\n",
    "bb_boxes1 = bb_boxes.copy(deep=True)\n",
    "bb_boxes1['xmin'] = (bb_boxes['xmin'] - p1[0])/(p2[0]-p1[0])*img.shape[1]\n",
    "bb_boxes1['xmax'] = (bb_boxes['xmax'] - p1[0])/(p2[0]-p1[0])*img.shape[1]\n",
    "bb_boxes1['ymin'] = (bb_boxes['ymin'] - p1[1])/(p3[1]-p1[1])*img.shape[0]\n",
    "bb_boxes1['ymax'] = (bb_boxes['ymax'] - p1[1])/(p3[1]-p1[1])*img.shape[0]\n",
    "plot_img_bbox(dst,bb_boxes1)\n",
    "\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Testing translation and stretching augmentations\n",
    "\n",
    "name,img,bb_boxes = load_image_name(df_vehicles,1,augmentation=False)\n",
    "img_mask =get_mask_segmentation(img,bb_boxes)\n",
    "\n",
    "plt.figure(figsize=(18,12))\n",
    "plt.subplot(2,2,1)\n",
    "plot_img_bbox(img,bb_boxes)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(img_mask[:,:,0])\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "#bb_boxes1 = bb_boxes.copy()\n",
    "dst,bb_boxes1 = stretch_image(img,bb_boxes,100)\n",
    "\n",
    "plt.imshow(dst)\n",
    "\n",
    "plot_img_bbox(dst,bb_boxes1)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "img_mask2 =get_mask_segmentation(dst,bb_boxes1)\n",
    "plt.imshow(img_mask2[:,:,0])\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_str,img,bb_boxes = load_image_name(df_vehicles,1,augmentation=False)\n",
    "img_mask =get_mask_segmentation(img,bb_boxes)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(img)\n",
    "plot_img_bbox(img,bb_boxes)\n",
    "plt.show()\n",
    "plot_image_mask(img,img_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training and test generators using augmentation\n",
    "def generate_train_batch(data,batch_size = 32):\n",
    "    \n",
    "    batch_images = np.zeros((batch_size, img_rows, img_cols, 3))\n",
    "    batch_masks = np.zeros((batch_size, img_rows, img_cols, 1))\n",
    "    while 1:\n",
    "        for i_batch in range(batch_size):\n",
    "            i_line = np.random.randint(len(data)-2000)\n",
    "            name,img,bb_boxes = load_image_name(df_vehicles,i_line,size=(img_cols, img_rows),\n",
    "                                                  augmentation=True, trans_range=50, scale_range=50)\n",
    "            img_mask = get_mask_segmentation(img,bb_boxes)\n",
    "            batch_images[i_batch] = img\n",
    "            batch_masks[i_batch] =img_mask\n",
    "        yield batch_images, batch_masks\n",
    "        \n",
    "\n",
    "def generate_test_batch(data,batch_size = 32):\n",
    "    batch_images = np.zeros((batch_size, img_rows, img_cols, 3))\n",
    "    batch_masks = np.zeros((batch_size, img_rows, img_cols, 1))\n",
    "    while 1:\n",
    "        for i_batch in range(batch_size):\n",
    "            i_line = np.random.randint(2000)\n",
    "            i_line = i_line+len(data)-2000\n",
    "            name,img,bb_boxes = load_image_name(df_vehicles,i_line, size=(img_cols, img_rows),\n",
    "                                                  augmentation=False,  trans_range=0, scale_range=0 )\n",
    "            img_mask = get_mask_segmentation(img,bb_boxes)\n",
    "            batch_images[i_batch] = img\n",
    "            batch_masks[i_batch] =img_mask\n",
    "        yield batch_images, batch_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Image size, \n",
    "img_rows = 640\n",
    "img_cols = 960\n",
    "\n",
    "#img_rows = 480\n",
    "#img_cols = 720\n",
    "#img_rows = 320\n",
    "#img_cols = 480\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing the generator\n",
    "training_gen = generate_train_batch(df_vehicles,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_img,batch_mask = next(training_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Plotting generator output\n",
    "for i in range(10):\n",
    "    im = np.array(batch_img[i],dtype=np.uint8)\n",
    "    im_mask = np.array(batch_mask[i],dtype=np.uint8)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(im_mask[:,:,0])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(cv2.bitwise_and(im,im,mask=im_mask));\n",
    "    plt.axis('off')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### IOU  coeff and loss calculation\n",
    "smooth=1.0\n",
    "def IOU_calc(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    \n",
    "    return 2*(intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def IOU_calc_loss(y_true, y_pred):\n",
    "    return -IOU_calc(y_true, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#based on repository https://github.com/orobix/retina-unet, \n",
    "#slightly modified to save GPU memory, original code in comments\n",
    "def get_gnet(drop=0.0):\n",
    "    inputs = Input((img_rows, img_cols,3))\n",
    "    inputs_norm = Lambda(lambda x: x/127.5 - 1.)\n",
    "  #  conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(inputs)  \n",
    "    conv1 = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(inputs)  \n",
    "    conv1 = Dropout(drop)(conv1)\n",
    "  #  conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv1)\n",
    "    conv1 = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(conv1)\n",
    "   # up1 = UpSampling2D(size=(2, 2))(conv1)\n",
    "  \n",
    "    conv2 = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(conv1)\n",
    "    conv2 = Dropout(drop)(conv2)\n",
    "    conv2 = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    #\n",
    "    conv3 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(pool2)\n",
    "    conv3 = Dropout(drop)(conv3)\n",
    "    conv3 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    #\n",
    "    conv4 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(pool3)\n",
    "    conv4 = Dropout(drop)(conv4)\n",
    "    conv4 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    #\n",
    "    conv5 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(pool4)\n",
    "    conv5 = Dropout(drop)(conv5)\n",
    "    conv5 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv5)\n",
    "    #\n",
    "    up6 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=3)\n",
    "    conv6 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(up6)\n",
    "    conv6 = Dropout(drop)(conv6)\n",
    "    conv6 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv6)\n",
    "    #\n",
    "    up7 = merge([UpSampling2D(size=(2, 2))(conv6), conv3], mode='concat', concat_axis=3)\n",
    "    conv7 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(up7)\n",
    "    conv7 = Dropout(drop)(conv7)\n",
    "    conv7 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv7)\n",
    "    #\n",
    "    up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=3)\n",
    "    conv8 = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(up8)\n",
    "    conv8 = Dropout(drop)(conv8)\n",
    "    conv8 = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(conv8)\n",
    "    #\n",
    "  #  pool4 = MaxPooling2D(pool_size=(2, 2))(conv8)\n",
    "\n",
    "  #  conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(pool4)\n",
    "    conv9 = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(conv8)\n",
    "    conv9 = Dropout(drop)(conv9)\n",
    " #   conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv9)\n",
    "    conv9 = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(conv9)\n",
    "\n",
    "    #\n",
    "    conv10 = Convolution2D(1, 1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input=inputs, output=conv10)\n",
    "\n",
    "   \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_gen = generate_train_batch(df_vehicles,8)\n",
    "model = get_gnet(drop=0.1)\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(lr=1e-4),  loss=IOU_calc_loss, metrics=[IOU_calc])\n",
    "history = model.fit_generator(training_gen, samples_per_epoch=1000,  nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Save model and weights IOU_calc: 0.6839\n",
    "model.save('model_Unet_640_960_e100.h5')\n",
    "\n",
    "model.save_weights(\"model_Unet_Weights_640_960_e100.h5\", overwrite=True)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 100 more epochs\n",
    "history = model.fit_generator(training_gen, samples_per_epoch=1000,  nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Save model and weights IOU_calc: 0.7262 \n",
    "model.save('model_Unet_640_960_e200.h5')\n",
    "\n",
    "model.save_weights(\"model_Unet_Weights_640_960_e200.h5\", overwrite=True)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 100 more epochs\n",
    "history = model.fit_generator(training_gen, samples_per_epoch=1000,  nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Save model and weights IOU_calc: 0.7539\n",
    "model.save('model_Unet_640_960_e300.h5')\n",
    "\n",
    "model.save_weights(\"model_Unet_Weights_640_960_e300.h5\", overwrite=True)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 100 more epochs\n",
    "history = model.fit_generator(training_gen, samples_per_epoch=1000,  nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Save model and weights IOU_calc: 0.7617\n",
    "model.save('model_Unet_640_960_e400.h5')\n",
    "\n",
    "model.save_weights(\"model_Unet_Weights_640_960_e400.h5\", overwrite=True)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 100 more epochs\n",
    "history = model.fit_generator(training_gen, samples_per_epoch=1000,  nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Save model and weights IOU_calc: 0.7757\n",
    "model.save('model_Unet_640_960_e500.h5')\n",
    "\n",
    "model.save_weights(\"model_Unet_Weights_640_960_e500.h5\", overwrite=True)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_adopted_unet():\n",
    "    inputs = Input((img_rows, img_cols,3))\n",
    "    inputs_norm = Lambda(lambda x: x/127.5 - 1.)\n",
    "    conv1 = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(inputs)\n",
    "    conv1 = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(pool1)\n",
    "    conv2 = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(pool2)\n",
    "    conv3 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(pool3)\n",
    "    conv4 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(pool4)\n",
    "    conv5 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv5)\n",
    "\n",
    "    up6 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=3)\n",
    "    conv6 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(up6)\n",
    "    conv6 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv6)\n",
    "\n",
    "    up7 = merge([UpSampling2D(size=(2, 2))(conv6), conv3], mode='concat', concat_axis=3)\n",
    "    conv7 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(up7)\n",
    "    conv7 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv7)\n",
    "\n",
    "    up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=3)\n",
    "    conv8 = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(up8)\n",
    "    conv8 = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(conv8)\n",
    "\n",
    "    up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=3)\n",
    "    conv9 = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(up9)\n",
    "    conv9 = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(conv9)\n",
    "\n",
    "    conv10 = Convolution2D(1, 1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input=inputs, output=conv10)\n",
    "\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_gen = generate_train_batch(df_vehicles,16)\n",
    "model = get_adopted_unet()\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(lr=1e-4),  loss=IOU_calc_loss, metrics=[IOU_calc])\n",
    "history = model.fit_generator(training_gen, samples_per_epoch=1000,  nb_epoch=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Save model and weights IOU_calc: 0.6989\n",
    "model.save('model_AdoptedUnet_640_960_e100.h5')\n",
    "\n",
    "model.save_weights(\"model_AdoptedUnet_Weights_640_960_e100.h5\", overwrite=True)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 100 more epochs\n",
    "history = model.fit_generator(training_gen, samples_per_epoch=1000,  nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Save model and weights IOU_calc: 0.7480\n",
    "model.save('model_AdoptedUnet_640_960_e200.h5')\n",
    "\n",
    "model.save_weights(\"model_AdoptedUnet_Weights_640_960_e200.h5\", overwrite=True)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 100 more epochs\n",
    "history = model.fit_generator(training_gen, samples_per_epoch=1000,  nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Save model and weights IOU_calc: 0.7674\n",
    "model.save('model_AdoptedUnet_640_960_e300.h5')\n",
    "\n",
    "model.save_weights(\"model_AdoptedUnet_Weights_640_960_e300.h5\", overwrite=True)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 100 more epochs\n",
    "history = model.fit_generator(training_gen, samples_per_epoch=1000,  nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Save model and weights IOU_calc: 0.7872\n",
    "model.save('model_AdoptedUnet_640_960_e400.h5')\n",
    "model.save_weights(\"model_AdoptedUnet_Weights_640_960_e400.h5\", overwrite=True)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 100 more epochs\n",
    "history = model.fit_generator(training_gen, samples_per_epoch=1000,  nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Save model and weightsIOU_calc: 0.8010 \n",
    "model.save('model_AdoptedUnet_640_960_e500.h5')\n",
    "model.save_weights(\"model_AdoptedUnet_Weights_640_960_e500.h5\", overwrite=True)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload GNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Image size, \n",
    "img_rows = 640\n",
    "img_cols = 960\n",
    "\n",
    "#img_rows = 480\n",
    "#img_cols = 720\n",
    "\n",
    "\n",
    "#recreate model and load trained weights\n",
    "#del model\n",
    "model = get_gnet()\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss=IOU_calc_loss, metrics=[IOU_calc])\n",
    "model.load_weights(\"model_Unet_Weights_640_960_e500.h5\")   \n",
    "   \n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Function for drawing bounding boxes, taken from Udacity\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        if ((np.max(nonzeroy)-np.min(nonzeroy)>50) & (np.max(nonzerox)-np.min(nonzerox)>50)):\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "            # Draw the box on the image       \n",
    "            cv2.rectangle(img, bbox[0], bbox[1], (0,0,255),6)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "def pred_for_img(img):\n",
    "    img = cv2.resize(img,(img_cols, img_rows))\n",
    "    img = np.reshape(img,(1,img_rows, img_cols,3))\n",
    "    pred = model.predict(img)\n",
    "    return pred,img[0]\n",
    "\n",
    "def get_BB_new_img(img):\n",
    "    # Take in RGB image\n",
    "    img  = np.array(img,dtype= np.uint8)\n",
    "    img_pred = np.array(255*pred[0],dtype=np.uint8)\n",
    "    heatmap = img_pred[:,:,0]\n",
    "    labels = label(heatmap)\n",
    "    draw_img = draw_labeled_bboxes(np.copy(img), labels)\n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Testing generator\n",
    "\n",
    "testing_gen = generate_test_batch(df_vehicles,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "%time pred_all= model.predict(batch_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Test on last frames of data\n",
    "\n",
    "batch_img,batch_mask = next(testing_gen)\n",
    "pred_all= model.predict(batch_img)\n",
    "np.shape(pred_all)\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    im = np.array(batch_img[i],dtype=np.uint8)\n",
    "    im_mask = np.array(255*batch_mask[i],dtype=np.uint8)\n",
    "    im_pred = np.array(255*pred_all[i],dtype=np.uint8)\n",
    "    \n",
    "    rgb_mask_pred = cv2.cvtColor(im_pred,cv2.COLOR_GRAY2RGB)\n",
    "    rgb_mask_pred[:,:,1:3] = 0*rgb_mask_pred[:,:,1:2]\n",
    "    rgb_mask_true= cv2.cvtColor(im_mask,cv2.COLOR_GRAY2RGB)\n",
    "    rgb_mask_true[:,:,0] = 0*rgb_mask_true[:,:,0]\n",
    "    rgb_mask_true[:,:,2] = 0*rgb_mask_true[:,:,2]\n",
    "    \n",
    "    img_pred = cv2.addWeighted(rgb_mask_pred,0.5,im,0.5,0)\n",
    "    img_true = cv2.addWeighted(rgb_mask_true,0.5,im,0.5,0)\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(im)\n",
    "    plt.title('Original image')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(img_true)\n",
    "    plt.title('Ground truth BB')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(img_pred)\n",
    "    plt.title('Predicted segmentation mask')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_img = 'test_images/test5.jpg'\n",
    "im = cv2.imread(test_img)\n",
    "im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "pred,im = pred_for_img(im)\n",
    "im  = np.array(im,dtype= np.uint8)\n",
    "im_pred = np.array(255*pred[0],dtype=np.uint8)\n",
    "rgb_mask_pred = cv2.cvtColor(im_pred,cv2.COLOR_GRAY2RGB)\n",
    "rgb_mask_pred[:,:,1:3] = 0*rgb_mask_pred[:,:,1:2]\n",
    "\n",
    "img_pred = cv2.addWeighted(rgb_mask_pred,0.85,im,1,0)\n",
    "\n",
    "\n",
    "draw_img = get_BB_new_img(im)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(im)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(img_pred)\n",
    "plt.title('Segmentation')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(draw_img)\n",
    "plt.title('Bounding Box')\n",
    "plt.axis('off');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload Adopted UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Image size, \n",
    "img_rows = 640\n",
    "img_cols = 960\n",
    "\n",
    "#img_rows = 480\n",
    "#img_cols = 720\n",
    "\n",
    "\n",
    "#recreate model and load trained weights\n",
    "#del model\n",
    "model = get_adopted_unet()\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss=IOU_calc_loss, metrics=[IOU_calc])\n",
    "model.load_weights(\"model_AdoptedUnet_Weights_640_960_e500.h5\")   \n",
    "   \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Test on last frames of data\n",
    "\n",
    "batch_img,batch_mask = next(testing_gen)\n",
    "pred_all= model.predict(batch_img)\n",
    "np.shape(pred_all)\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    im = np.array(batch_img[i],dtype=np.uint8)\n",
    "    im_mask = np.array(255*batch_mask[i],dtype=np.uint8)\n",
    "    im_pred = np.array(255*pred_all[i],dtype=np.uint8)\n",
    "    \n",
    "    rgb_mask_pred = cv2.cvtColor(im_pred,cv2.COLOR_GRAY2RGB)\n",
    "    rgb_mask_pred[:,:,1:3] = 0*rgb_mask_pred[:,:,1:2]\n",
    "    rgb_mask_true= cv2.cvtColor(im_mask,cv2.COLOR_GRAY2RGB)\n",
    "    rgb_mask_true[:,:,0] = 0*rgb_mask_true[:,:,0]\n",
    "    rgb_mask_true[:,:,2] = 0*rgb_mask_true[:,:,2]\n",
    "    \n",
    "    img_pred = cv2.addWeighted(rgb_mask_pred,0.5,im,0.5,0)\n",
    "    img_true = cv2.addWeighted(rgb_mask_true,0.5,im,0.5,0)\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(im)\n",
    "    plt.title('Original image')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(img_true)\n",
    "    plt.title('Ground truth BB')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(img_pred)\n",
    "    plt.title('Predicted segmentation mask')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_img = 'test_images/test5.jpg'\n",
    "im = cv2.imread(test_img)\n",
    "im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "pred,im = pred_for_img(im)\n",
    "im  = np.array(im,dtype= np.uint8)\n",
    "im_pred = np.array(255*pred[0],dtype=np.uint8)\n",
    "rgb_mask_pred = cv2.cvtColor(im_pred,cv2.COLOR_GRAY2RGB)\n",
    "rgb_mask_pred[:,:,1:3] = 0*rgb_mask_pred[:,:,1:2]\n",
    "\n",
    "img_pred = cv2.addWeighted(rgb_mask_pred,0.85,im,1,0)\n",
    "\n",
    "\n",
    "draw_img = get_BB_new_img(im)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(im)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(img_pred)\n",
    "plt.title('Segmentation')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(draw_img)\n",
    "plt.title('Bounding Box')\n",
    "plt.axis('off');"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
